{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3149bde4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/impulse/Documents/impulsegpt/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.1+cu128\n"
     ]
    }
   ],
   "source": [
    "import impulsegpt_sdpa\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchinfo import summary\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
    "#import char_tokenizer\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e43b0029",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 6)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_capability()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48e9e1f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cpu')\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(\"Using CUDA\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "    print(\"Using MPS\")\n",
    "else:\n",
    "    print(\"Using CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5429ebef",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = torch.rand((4, 8, 8, 32), dtype=torch.bfloat16, device=device)\n",
    "k = torch.rand((4, 8, 8, 32), dtype=torch.bfloat16, device=device)\n",
    "v = torch.rand((4, 8, 8, 32), dtype=torch.bfloat16, device=device)\n",
    "\n",
    "with nn.attention.sdpa_kernel(nn.attention.SDPBackend.FLASH_ATTENTION):\n",
    "    nn.functional.scaled_dot_product_attention(q, k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d805b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = impulsegpt_sdpa.Config()\n",
    "config.ctx_len = 128\n",
    "config.n_layers = 12\n",
    "config.d_model = 768\n",
    "config.n_heads = 12\n",
    "config.n_kv_heads = 4\n",
    "config.vocab = 50000\n",
    "config.gpa = True\n",
    "\n",
    "enable_mixed_pricision = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97486ab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model vocab set to: 21128, Embedding size: 16226304\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('google-bert/bert-base-chinese')\n",
    "#tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/gpt-neo-125m\")\n",
    "collator = DataCollatorWithPadding(tokenizer, 'max_length', config.ctx_len, return_tensors='pt')\n",
    "\n",
    "config.vocab = len(tokenizer.vocab)\n",
    "print(f\"Model vocab set to: {config.vocab}, Embedding size: {config.d_model * config.vocab}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32d4055a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(\"roneneldan/TinyStories\")\n",
    "ds = ds['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "235a17c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length before filter: 2119719\n",
      "{'input_ids': tensor([  101,   100,  8542,   117,   143,  9929,  9375,  8617,  8168,   100,\n",
      "          148, 11477,   143, 10564,  8303,  8268,  8217, 11908, 10083,   119,\n",
      "          100,   153, 10654,  8233,  9947,  9796,  9049,  8317,  9766,  8228,\n",
      "         8942,  8663,  8233,  8815,  8808, 10254,  8233,  9947, 11167,  8458,\n",
      "         8187,   119,   100, 12733,  8303,  8228,  8697,  8174, 10564,  8303,\n",
      "         8268,  8663, 11908, 11303,  8175,   117,  8968,  9374,  8792, 10086,\n",
      "         8168,  9342,  8220,   143, 10288,  8626,  8281, 11908, 12060,   119,\n",
      "          100,  8997,  8511,  8228, 11908, 11303,  8175,  8256,  8385,   117,\n",
      "          107,   100,   117,   100,   148, 11477,  8554, 10564,  8303,  8268,\n",
      "          119,   100,  8357,  8697,  8233,  8663,  8450,  8256,  9342,  8220,\n",
      "         8422, 12060,   136,   107,   100, 11303,  8175,  9158,  9729,  8168,\n",
      "         8256,  8385,   117,   107,   100,   117,   100,   117,  8997,  9109,\n",
      "         8697,  8174, 10564,  8303,  8268,  8256,  8533,   102])}\n",
      "Train data length: 2119719\n"
     ]
    }
   ],
   "source": [
    "print(f\"Length before filter: {len(ds)}\")\n",
    "#ds = ds.filter(lambda t: len(t['text']) < (config.ctx_len*2))\n",
    "ds = ds.map(lambda t: tokenizer(t['text'], \n",
    "                                truncation=True, \n",
    "                                max_length=config.ctx_len,\n",
    "                                return_overflowing_tokens=False,\n",
    "                                return_length=True), batched=True)\n",
    "ds = ds.remove_columns(['text','token_type_ids','attention_mask', 'length'])\n",
    "ds = ds.with_format('torch')\n",
    "\n",
    "print(ds[0])\n",
    "print(f\"Train data length: {len(ds)}\")\n",
    "#print(f\"Validation data length: {len(ds['validation'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32380061",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "ImpulseGPT                               --\n",
       "├─Embedding: 1-1                         16,226,304\n",
       "├─ModuleList: 1-2                        --\n",
       "│    └─Layer: 2-1                        --\n",
       "│    │    └─RoPE: 3-1                    --\n",
       "│    │    └─RoPE: 3-2                    --\n",
       "│    │    └─Linear: 3-3                  589,824\n",
       "│    │    └─Linear: 3-4                  196,608\n",
       "│    │    └─Linear: 3-5                  196,608\n",
       "│    │    └─Linear: 3-6                  590,592\n",
       "│    │    └─Sequential: 3-7              4,722,432\n",
       "│    │    └─Dropout: 3-8                 --\n",
       "│    └─Layer: 2-2                        --\n",
       "│    │    └─RoPE: 3-9                    --\n",
       "│    │    └─RoPE: 3-10                   --\n",
       "│    │    └─Linear: 3-11                 589,824\n",
       "│    │    └─Linear: 3-12                 196,608\n",
       "│    │    └─Linear: 3-13                 196,608\n",
       "│    │    └─Linear: 3-14                 590,592\n",
       "│    │    └─Sequential: 3-15             4,722,432\n",
       "│    │    └─Dropout: 3-16                --\n",
       "│    └─Layer: 2-3                        --\n",
       "│    │    └─RoPE: 3-17                   --\n",
       "│    │    └─RoPE: 3-18                   --\n",
       "│    │    └─Linear: 3-19                 589,824\n",
       "│    │    └─Linear: 3-20                 196,608\n",
       "│    │    └─Linear: 3-21                 196,608\n",
       "│    │    └─Linear: 3-22                 590,592\n",
       "│    │    └─Sequential: 3-23             4,722,432\n",
       "│    │    └─Dropout: 3-24                --\n",
       "│    └─Layer: 2-4                        --\n",
       "│    │    └─RoPE: 3-25                   --\n",
       "│    │    └─RoPE: 3-26                   --\n",
       "│    │    └─Linear: 3-27                 589,824\n",
       "│    │    └─Linear: 3-28                 196,608\n",
       "│    │    └─Linear: 3-29                 196,608\n",
       "│    │    └─Linear: 3-30                 590,592\n",
       "│    │    └─Sequential: 3-31             4,722,432\n",
       "│    │    └─Dropout: 3-32                --\n",
       "│    └─Layer: 2-5                        --\n",
       "│    │    └─RoPE: 3-33                   --\n",
       "│    │    └─RoPE: 3-34                   --\n",
       "│    │    └─Linear: 3-35                 589,824\n",
       "│    │    └─Linear: 3-36                 196,608\n",
       "│    │    └─Linear: 3-37                 196,608\n",
       "│    │    └─Linear: 3-38                 590,592\n",
       "│    │    └─Sequential: 3-39             4,722,432\n",
       "│    │    └─Dropout: 3-40                --\n",
       "│    └─Layer: 2-6                        --\n",
       "│    │    └─RoPE: 3-41                   --\n",
       "│    │    └─RoPE: 3-42                   --\n",
       "│    │    └─Linear: 3-43                 589,824\n",
       "│    │    └─Linear: 3-44                 196,608\n",
       "│    │    └─Linear: 3-45                 196,608\n",
       "│    │    └─Linear: 3-46                 590,592\n",
       "│    │    └─Sequential: 3-47             4,722,432\n",
       "│    │    └─Dropout: 3-48                --\n",
       "│    └─Layer: 2-7                        --\n",
       "│    │    └─RoPE: 3-49                   --\n",
       "│    │    └─RoPE: 3-50                   --\n",
       "│    │    └─Linear: 3-51                 589,824\n",
       "│    │    └─Linear: 3-52                 196,608\n",
       "│    │    └─Linear: 3-53                 196,608\n",
       "│    │    └─Linear: 3-54                 590,592\n",
       "│    │    └─Sequential: 3-55             4,722,432\n",
       "│    │    └─Dropout: 3-56                --\n",
       "│    └─Layer: 2-8                        --\n",
       "│    │    └─RoPE: 3-57                   --\n",
       "│    │    └─RoPE: 3-58                   --\n",
       "│    │    └─Linear: 3-59                 589,824\n",
       "│    │    └─Linear: 3-60                 196,608\n",
       "│    │    └─Linear: 3-61                 196,608\n",
       "│    │    └─Linear: 3-62                 590,592\n",
       "│    │    └─Sequential: 3-63             4,722,432\n",
       "│    │    └─Dropout: 3-64                --\n",
       "│    └─Layer: 2-9                        --\n",
       "│    │    └─RoPE: 3-65                   --\n",
       "│    │    └─RoPE: 3-66                   --\n",
       "│    │    └─Linear: 3-67                 589,824\n",
       "│    │    └─Linear: 3-68                 196,608\n",
       "│    │    └─Linear: 3-69                 196,608\n",
       "│    │    └─Linear: 3-70                 590,592\n",
       "│    │    └─Sequential: 3-71             4,722,432\n",
       "│    │    └─Dropout: 3-72                --\n",
       "│    └─Layer: 2-10                       --\n",
       "│    │    └─RoPE: 3-73                   --\n",
       "│    │    └─RoPE: 3-74                   --\n",
       "│    │    └─Linear: 3-75                 589,824\n",
       "│    │    └─Linear: 3-76                 196,608\n",
       "│    │    └─Linear: 3-77                 196,608\n",
       "│    │    └─Linear: 3-78                 590,592\n",
       "│    │    └─Sequential: 3-79             4,722,432\n",
       "│    │    └─Dropout: 3-80                --\n",
       "│    └─Layer: 2-11                       --\n",
       "│    │    └─RoPE: 3-81                   --\n",
       "│    │    └─RoPE: 3-82                   --\n",
       "│    │    └─Linear: 3-83                 589,824\n",
       "│    │    └─Linear: 3-84                 196,608\n",
       "│    │    └─Linear: 3-85                 196,608\n",
       "│    │    └─Linear: 3-86                 590,592\n",
       "│    │    └─Sequential: 3-87             4,722,432\n",
       "│    │    └─Dropout: 3-88                --\n",
       "│    └─Layer: 2-12                       --\n",
       "│    │    └─RoPE: 3-89                   --\n",
       "│    │    └─RoPE: 3-90                   --\n",
       "│    │    └─Linear: 3-91                 589,824\n",
       "│    │    └─Linear: 3-92                 196,608\n",
       "│    │    └─Linear: 3-93                 196,608\n",
       "│    │    └─Linear: 3-94                 590,592\n",
       "│    │    └─Sequential: 3-95             4,722,432\n",
       "│    │    └─Dropout: 3-96                --\n",
       "├─Linear: 1-3                            16,247,432\n",
       "=================================================================\n",
       "Total params: 108,026,504\n",
       "Trainable params: 108,026,504\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = impulsegpt_sdpa.ImpulseGPT(config=config).to(device)\n",
    "model.compile()\n",
    "#model = torch.load('ckpt/ts-64-1.pt')\n",
    "summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b74eff3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataset, model, loss_fn, optimizer, epochs:int=1, batch_size:int=16, training_divides:int=10, scaler:torch.amp.GradScaler=None, logger:SummaryWriter=None):\n",
    "    model.train()\n",
    "    print(f\"Start training for {epochs} epochs with {len(dataset)} rows of data each.\")\n",
    "    for s in range(epochs):\n",
    "        for chunk in range(training_divides):\n",
    "            print(f\"Training on {chunk+1} of {training_divides} data chunks\")\n",
    "            dataloader = DataLoader(dataset=dataset.shard(num_shards=training_divides, index=chunk),\n",
    "                                    collate_fn=collator, \n",
    "                                    batch_size=batch_size, \n",
    "                                    num_workers=16)\n",
    "            pbar = tqdm(enumerate(dataloader), total=len(dataloader), desc=f\"Epoch {s+1} of {epochs}\")\n",
    "            for batch, row in pbar:\n",
    "                step_loss = 0\n",
    "                num_rows = row['input_ids'].shape[1] - 1\n",
    "                for t in range(num_rows):\n",
    "                    context = row['input_ids'][...,:t+1].to(device)\n",
    "                    y = row['input_ids'][...,t+1].to(device)\n",
    "\n",
    "                    with torch.autocast(device_type='cuda', \n",
    "                                        dtype=torch.bfloat16, \n",
    "                                        enabled=enable_mixed_pricision):\n",
    "                        y_hat = model(context)\n",
    "                        loss = loss_fn(y_hat, y)\n",
    "                        scaler.scale(loss).backward()\n",
    "                        scaler.step(optimizer)\n",
    "                        scaler.update()\n",
    "                        optimizer.zero_grad()\n",
    "                        step_loss += loss.item()\n",
    "                step_loss /= num_rows\n",
    "                if logger:\n",
    "                    logger.add_scalar('Loss', step_loss, batch+1)\n",
    "                pbar.set_postfix({'Loss':step_loss})\n",
    "        torch.save(model, f\"ckpt/impgpt-{config.ctx_len}-{chunk}.pt\")\n",
    "    if logger:\n",
    "        logger.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "990e7be1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training for 1 epochs with 2119719 rows of data each.\n",
      "Training on 1 of 100 data chunks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 of 1:   5%|▌         | 72/1325 [05:03<1:28:05,  4.22s/it, Loss=6.05]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m      9\u001b[39m writer = SummaryWriter()\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m nn.attention.sdpa_kernel(nn.attention.SDPBackend.FLASH_ATTENTION):\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscaler\u001b[49m\u001b[43m=\u001b[49m\u001b[43mscalar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining_divides\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 25\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(dataset, model, loss_fn, optimizer, epochs, batch_size, training_divides, scaler, logger)\u001b[39m\n\u001b[32m     23\u001b[39m loss = loss_fn(y_hat, y)\n\u001b[32m     24\u001b[39m scaler.scale(loss).backward()\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m \u001b[43mscaler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     26\u001b[39m scaler.update()\n\u001b[32m     27\u001b[39m optimizer.zero_grad()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/impulsegpt/.venv/lib/python3.12/site-packages/torch/amp/grad_scaler.py:461\u001b[39m, in \u001b[36mGradScaler.step\u001b[39m\u001b[34m(self, optimizer, *args, **kwargs)\u001b[39m\n\u001b[32m    455\u001b[39m     \u001b[38;5;28mself\u001b[39m.unscale_(optimizer)\n\u001b[32m    457\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[32m    458\u001b[39m     \u001b[38;5;28mlen\u001b[39m(optimizer_state[\u001b[33m\"\u001b[39m\u001b[33mfound_inf_per_device\u001b[39m\u001b[33m\"\u001b[39m]) > \u001b[32m0\u001b[39m\n\u001b[32m    459\u001b[39m ), \u001b[33m\"\u001b[39m\u001b[33mNo inf checks were recorded for this optimizer.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m461\u001b[39m retval = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_maybe_opt_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    463\u001b[39m optimizer_state[\u001b[33m\"\u001b[39m\u001b[33mstage\u001b[39m\u001b[33m\"\u001b[39m] = OptState.STEPPED\n\u001b[32m    465\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/impulsegpt/.venv/lib/python3.12/site-packages/torch/amp/grad_scaler.py:355\u001b[39m, in \u001b[36mGradScaler._maybe_opt_step\u001b[39m\u001b[34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[39m\n\u001b[32m    347\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_maybe_opt_step\u001b[39m(\n\u001b[32m    348\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    349\u001b[39m     optimizer: torch.optim.Optimizer,\n\u001b[32m   (...)\u001b[39m\u001b[32m    352\u001b[39m     **kwargs: Any,\n\u001b[32m    353\u001b[39m ) -> Optional[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[32m    354\u001b[39m     retval: Optional[\u001b[38;5;28mfloat\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m355\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moptimizer_state\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfound_inf_per_device\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    356\u001b[39m         retval = optimizer.step(*args, **kwargs)\n\u001b[32m    357\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/impulsegpt/.venv/lib/python3.12/site-packages/torch/amp/grad_scaler.py:355\u001b[39m, in \u001b[36m<genexpr>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m    347\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_maybe_opt_step\u001b[39m(\n\u001b[32m    348\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    349\u001b[39m     optimizer: torch.optim.Optimizer,\n\u001b[32m   (...)\u001b[39m\u001b[32m    352\u001b[39m     **kwargs: Any,\n\u001b[32m    353\u001b[39m ) -> Optional[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[32m    354\u001b[39m     retval: Optional[\u001b[38;5;28mfloat\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m355\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28msum\u001b[39m(\u001b[43mv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m optimizer_state[\u001b[33m\"\u001b[39m\u001b[33mfound_inf_per_device\u001b[39m\u001b[33m\"\u001b[39m].values()):\n\u001b[32m    356\u001b[39m         retval = optimizer.step(*args, **kwargs)\n\u001b[32m    357\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), \n",
    "                              lr=5e-4, \n",
    "                              betas=(0.9, 0.95),\n",
    "                              weight_decay=0.1)\n",
    "# For mixed precision\n",
    "scalar = torch.amp.GradScaler('cuda')\n",
    "\n",
    "writer = SummaryWriter()\n",
    "\n",
    "\n",
    "with nn.attention.sdpa_kernel(nn.attention.SDPBackend.FLASH_ATTENTION):\n",
    "    train(ds, model, loss_fn, optimizer, epochs=1, batch_size=16, scaler=scalar, training_divides=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff021e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"ckpt/impgpt-final-1.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6f3071",
   "metadata": {},
   "outputs": [],
   "source": [
    "#start_x = torch.tensor(tokenizer.encode('Once upon a time')).unsqueeze(dim=0).to(device=device)\n",
    "#print(start_x)\n",
    "start_ids = torch.tensor([[ 101,  100, 8644, 8224,  143, 8759]]).to(device)\n",
    "max_length = 64\n",
    "y = model.generate(start_ids, max_length=max_length, top_k=64, temp=0.75)\n",
    "print(y)\n",
    "txt = tokenizer.decode(y[0].tolist(), skip_special_tokens=True)\n",
    "print(y.shape)\n",
    "print(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5a47b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = model(start_ids)\n",
    "prob = nn.functional.softmax(y, dim=-1).cpu().detach().squeeze()\n",
    "token_max = torch.argmax(prob)\n",
    "print(token_max)\n",
    "plt.plot(prob)\n",
    "tokenizer.decode([token_max.tolist()])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "impulsegpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
