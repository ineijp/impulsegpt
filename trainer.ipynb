{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3149bde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import impulsegpt\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchinfo import summary\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e9e1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device('cpu')\n",
    "# if torch.cuda.is_available():\n",
    "#     device = torch.device('cuda')\n",
    "#     print(\"Using CUDA\")\n",
    "# elif torch.backends.mps.is_available():\n",
    "#     device = torch.device('mps')\n",
    "#     print(\"Using MPS\")\n",
    "# else:\n",
    "#     print(\"Using CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4749ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d805b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = impulsegpt.Config()\n",
    "config.ctx_len = 64\n",
    "config.n_layers = 6\n",
    "config.d_model = 512\n",
    "config.n_heads = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d105e062",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_dir = 'D:/dataset/tiny.txt'\n",
    "data_dir = './train_data/wkz8.txt'\n",
    "\n",
    "with open(data_dir, 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "# Count unique characters\n",
    "unique_chars = set(text)\n",
    "num_unique_chars = len(unique_chars)\n",
    "\n",
    "config.vocab = num_unique_chars\n",
    "\n",
    "print(f'Length of text: {len(text)}')\n",
    "print(f\"Number of unique characters in the file: {num_unique_chars}\")\n",
    "print(\"Unique characters:\", ''.join(sorted(unique_chars)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4132fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \" \".join(text.split())\n",
    "print(len(text))\n",
    "char = ' '\n",
    "count = 0\n",
    "for t in text:\n",
    "    if t == char:\n",
    "        count += 1\n",
    "print(f\"number of char:{char} is {count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97486ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "character_to_index = {char: i for i, char in enumerate(unique_chars)}\n",
    "index_to_character = {i: char for i, char in enumerate(unique_chars)}\n",
    "\n",
    "def encode(x):\n",
    "    return [character_to_index[i] for i in x]\n",
    "\n",
    "def decode(x):\n",
    "    return [index_to_character[i] for i in x]\n",
    "\n",
    "def decode_tensor(x):\n",
    "    return ''.join([index_to_character[i.item()] for i in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107d1ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_text = torch.tensor(encode(text), dtype=torch.int, device=device)\n",
    "\n",
    "# Create train-validation split (90-10)\n",
    "n = int(0.9 * len(encoded_text))\n",
    "train_data = encoded_text[:n]\n",
    "val_data = encoded_text[n:]\n",
    "\n",
    "print(f\"Train data length: {len(train_data)}\")\n",
    "print(f\"Validation data length: {len(val_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f6b0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(data, batch_size, context_length):\n",
    "    batch = []\n",
    "    for b in range(batch_size):\n",
    "        i = torch.randint(0, len(data) - context_length - 1, (1,))\n",
    "        batch.append(data[i:i+context_length+1])\n",
    "    return torch.stack(batch)\n",
    "\n",
    "def get_data(batches):\n",
    "    num_batch, ctx_len = batches.shape\n",
    "    context = []\n",
    "    label = []\n",
    "    for t in range(ctx_len-1):\n",
    "        context.append(torch.stack([batches[i][:t+1] for i in range(num_batch)]).to(device))\n",
    "        label.append(torch.stack([batches[i][t+1] for i in range(num_batch)]).type(torch.LongTensor).to(device))\n",
    "    return context, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39132ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = impulsegpt.ImpulseGPT(config=config).to(device)\n",
    "loss_fn = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.00005)\n",
    "summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5b1ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataset, model, loss_fn, optimizer, steps:int, num_batch=4):\n",
    "    model.train()\n",
    "    print(f\"Start training with {steps} steps\")\n",
    "    pbar = tqdm(range(steps))\n",
    "    for step in pbar:\n",
    "        batch = get_batch(dataset, num_batch, config.ctx_len)\n",
    "        context, label = get_data(batch)\n",
    "        step_loss = 0\n",
    "        for i in range(len(label)):\n",
    "            pred = model(context[i])\n",
    "            loss = loss_fn(pred, label[i])\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            step_loss += loss.item()\n",
    "        step_loss = step_loss / len(label)\n",
    "        pbar.set_postfix({'Loss:':step_loss})\n",
    "        # if step % 25 == 0:\n",
    "        #     print(f\"Step {step}: Loss = {step_loss}\")\n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990e7be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(train_data, model, loss_fn, optimizer, steps = 128, num_batch=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6f3071",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_x = torch.tensor(encode('æˆ‘')).unsqueeze(dim=0).to(device=device)\n",
    "\n",
    "max_length = 60\n",
    "y = model.generate(start_x, max_length=max_length, top_k=32)\n",
    "txt = decode_tensor(y[0])\n",
    "print(y.shape)\n",
    "print(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5a47b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = model(start_x)\n",
    "prob = nn.functional.softmax(y, dim=-1).cpu().detach().squeeze()\n",
    "token_max = torch.argmax(prob)\n",
    "print(token_max)\n",
    "plt.plot(prob)\n",
    "decode_tensor([token_max])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb32536d",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlbase",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
